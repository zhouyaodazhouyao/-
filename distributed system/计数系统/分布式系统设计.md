# 分布式计数系统设计

背景：对B站视频的观看量能进行近实时的计数（同类问题：对微服务的调用量进行计数、对头条的粉丝或点赞数进行计数、对企业的核心业务指标进行计数）

### 1.需求收集

**场景用例**

谁用这个系统？用户如何用这个系统？

**量级规模（读/写）**

每秒查询请求？每个查询请求多少数据？每秒处理多少个视频观看记录？流量模式？是否有流量高峰？

**性能**

预期从写入到读取数据的延迟（多久看到更新）？预期p99读请求延迟是多少？高可用性（一般隐含）

**成本**

开发成本？运维成本？

### 2.总体架构设计

[^功能需求]: 系统设计初衷想要的功能，开发人员必须实现

```
写入API：
countViewEvent(videoId);
countEvent(videoId, eventType);("view","like","share")
processEvent(videoId, eventType, func);("count","sum","avg")
processEvents(listOfEvents);
```

```
查询需求API：
getViewsCount(videoId, startTime, endTime);
getCount(videoId, eventType, startTime, endTime);
getStats(videoId, eventType, func, startTime, endTime);
```

[^非功能需求]: 与系统要完成的任务无关，用户的其他期望和要求，往往决定一个系统的质量好坏，常见的有高性能、高可用、可扩展、成本和可维护性

| 规模   | 每秒处理1w+视频点击观看记录                          |
| ------ | ---------------------------------------------------- |
| 性能1  | 写入/读取毫秒级延迟                                  |
| 性能2  | 写入到读取更新分钟级延迟，**近实时流处理，最终一致** |
| 高可用 | 无单点失败                                           |
| 可扩展 | 水平按需扩展                                         |
| 成本   | 开源低成本                                           |

简化架构

用户----->浏览器------>计数服务------->数据库

用户----->浏览器------>查询服务------->数据库

### 3.存储设计

#### 存什么？

1.单个事件（每次点击）

| VideoId | Timestamp           | ...  |
| ------- | ------------------- | ---- |
| A       | 2020-05-21 16:17:21 | ...  |
| A       | 2020-05-21 16:17:32 | ...  |
| A       | 2020-05-21 16:17:40 | ...  |
| B       | 2020-05-21 16:22:47 | ...  |

**优点**：可以快速写入；按需聚合运算

**缺点**：查询慢；耗存储



2.聚合数据（例如每分钟）

| VideoId | Timestamp        | count |
| ------- | ---------------- | ----- |
| A       | 2020-05-21 16:17 | 3     |
| B       | 2020-05-21 16:22 | 1     |

**优点**：查询快；存储少

**缺点**：只能按已聚合方式查询；需实时聚合运算；出错修复无法简单修复

#### 数据库选型

主要基于非功能需求

- **可扩展**——根据读写规模按需扩展
- **高性能**——快速读写
- **高可用**——不丢数据，灾难恢复
- **一致性折衷**
- 数据模型易于升级
- 成本
- 开发者学习门槛

##### 1.SQL数据库+客户端嵌入代理

![count-database-1](/Users/shuuyou/just-for-review-and-zhuangB/distributed system/count-database-1.png)

为了避免sharding和主从复制引入的复杂性，可以引入数据库访问代理，以客户库的形式嵌入到服务当中。（**ShardingSphere**）

**缺点**：引入了很多复杂性，包括手工sharding、引入主从复制机制、引入数据库访问代理和配置中心、Resharding人工导入数据等

##### 2.NoSql数据库（Cassandra）

![count-database-nosql](/Users/shuuyou/just-for-review-and-zhuangB/distributed system/count-database-nosql.png)

节点对等，节点之间定期交换信息（**gossip协议**），哈希算法使用的是**一致性哈希算法**；协调者可以按照某种选举方式选出来；读取和写入都直接经过协调者，读取使用仲裁读（Quorum read：多数返回结果一致即返回），写入由协调者判断数据属于哪一个节点，然后写入该节点中，同时为了高可用，会复制几份（**复制因子（Replication）**可配置）到其他节点，使用仲裁写（Quorum write：多数节点写入成功即视为成功）。

**优点**：线性扩容，无需人工干预；支持跨数据中心

**缺点**：运维管理复杂

#### 表设计

**1.SQL数据库**

| VideoId | Name   | ...  | SpaceId |
| ------- | ------ | ---- | ------- |
| X       | 马保国 | ...  | 123     |

Video_Info表

| VideoId | Timestamp | count |
| ------- | --------- | ----- |
| X       | 15:00     | 2     |
| X       | 16:00     | 3     |
| X       | 17:00     | 6     |

Video_status表

| SpaceId | Name   | ...  |
| ------- | ------ | ---- |
| 123     | 马保国 | ...  |

Space_Info表

**2.NoSQL数据库**

| VideoId+Date | SpaceName | VideoName | 15:00 | 16:00 | 17:00 | ...  |
| ------------ | --------- | --------- | ----- | ----- | ----- | ---- |
| X-2020.05.21 | 马保国    | 马保国    | 2     | 3     | 6     | ...  |

### 4.计数服务的实现

- **可扩展**：Partitioning/Sharding
- **高性能吞吐**：内存计算，Batch批处理
- **高可靠**：持久化，Replication，checkpointing

![count-service](/Users/shuuyou/just-for-review-and-zhuangB/distributed system/count-service.png)

[^图1]: counting consumer 详细设计

![Data-Ingestion-Path](/Users/shuuyou/just-for-review-and-zhuangB/distributed system/Data-Ingestion-Path.png)

[^图2]: 数据接收路径

### 5.查询服务的实现

![query-service](/Users/shuuyou/just-for-review-and-zhuangB/distributed system/query-service.png)

### 6.技术栈选型

- Api Gateway：NetFlix Zuul网关 / Spring Cloud Gateway
- Api前置负载均衡器：F5 / SLB负载均衡器（阿里云）
- Counting Service / Query Service / Counting Consumer：Spring Boot
- 服务发现：NetFlix Eureka
- 客户端软负载：NetFlix Ribbon
- 缓存：Redis
- MQ：Kafka
- 存储数据：Cassandra / HBase
- 线下计算：Hadoop / 对象存储OSS（阿里云）

### 7.进一步考量和总结

- **如何定位系统瓶颈？**

  性能和压力测试，找出潜在的性能、内存和多线程问题，同时在基础性能基础上进行性能调优；还可以对生产部署进行容量估算，以确定申请多少软硬件资源

- **如何监控系统健康状况？**

  细粒度埋点监控，对核心服务的调用量，调用延迟和错误数都要监控起来；硬件资源需监控的有CPU、内存和磁盘的利用率；如果使用java语言，JVM的垃圾回收也要监控；MQ的消息堆积情况；

- **如何监控慢消费？解决？**

  消息队列设计中有解释

- **如何解决热分区问题？**

  添加时间戳，按照每小时分摊到不同分区

分布式基本概念

功能需求、非功能需求、读写路径、分布式数据存储、sharding/replication、消息队列、消费者、负载均衡、服务发现、缓存、流式计算